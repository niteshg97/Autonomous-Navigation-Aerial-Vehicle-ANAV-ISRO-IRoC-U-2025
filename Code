import cv2
import numpy as np
from ultralytics import YOLO
import math

PIXEL_TO_CM = 0.1
TOLERANCE_CM = 2.0   # Tolerance in centimeters
ALPHA = 0.7

class YOLOv8Detector:
    def __init__(self, model_path='yolov8n.pt'):
        # Load the YOLOv8 model (it will detect the ground feature for Hovering/Navigation)
        self.model = YOLO(model_path)

    def detect_image(self, frame):
        """
        Detect objects in the frame using YOLOv8.
        Returns a list of detections with:
        (class_name, confidence, center_x, center_y, (x1, y1, x2, y2))
        """
        results = self.model.predict(frame, verbose=False)
        result = results[0]
        detections = result.boxes.data.cpu().numpy() if hasattr(result.boxes.data, 'cpu') else result.boxes.data.numpy()
        output = []
        for detection in detections:
            x1, y1, x2, y2, conf, cls = detection
            center_x = int((x1 + x2) / 2)
            center_y = int((y1 + y2) / 2)
            class_name = (
                result.names[int(cls)]
                if result.names and int(cls) in result.names
                else str(int(cls))
            )
            output.append((class_name, conf, center_x, center_y, (int(x1), int(y1), int(x2), int(y2))))
        return output

def draw_fixed_marker(frame, fixed_position):
    fx, fy = fixed_position
    cv2.circle(frame, (fx, fy), 5, (255, 0, 0), -1)
    cv2.line(frame, (fx - 15, fy), (fx + 15, fy), (255, 0, 0), 2)
    cv2.line(frame, (fx, fy - 15), (fx, fy + 15), (255, 0, 0), 2)
    cv2.putText(frame, "Fixed", (fx + 10, fy + 20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 2)

def detect_and_control_ANAV(detector):
    cap = cv2.VideoCapture(1)  # or 1 for an external camera(NAV/RGB)
    fixed_position = None  
    prev_gray = None
    prev_fused_center = None  

    # Kalman filter Initialization
    kalman = cv2.KalmanFilter(4, 2)
    kalman.measurementMatrix = np.array([[1, 0, 0, 0],
                                         [0, 1, 0, 0]], np.float32) 
    kalman.transitionMatrix = np.array([[1, 0, 1, 0],
                                        [0, 1, 0, 1],
                                        [0, 0, 1, 0],
                                        [0, 0, 0, 1]], np.float32)
    kalman.processNoiseCov = np.eye(4, dtype=np.float32) * 0.03
    kalman.measurementNoiseCov = np.eye(2, dtype=np.float32) * 0.5
    kalman.errorCovPost = np.eye(4, dtype=np.float32)

    print("Starting detection. Press 'q' to quit.")
    while True:
        ret, frame = cap.read()
        if not ret:
            break
        current_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

        # identifies hovering position
        if fixed_position is None:
            h, w = frame.shape[:2]
            fixed_position = (w // 2, h // 2)
        draw_fixed_marker(frame, fixed_position)

        # detection
        detections = detector.detect_image(frame)

        if detections:
            obj_class, conf, yolo_x, yolo_y, box = detections[0]
            fused_x, fused_y = yolo_x, yolo_y
            if prev_gray is not None and prev_fused_center is not None:
                x1, y1, x2, y2 = box
                roi = current_gray[y1:y2, x1:x2]
                roi_points = cv2.goodFeaturesToTrack(roi, maxCorners=10, qualityLevel=0.01, minDistance=5)

                if roi_points is not None:
                    roi_points = roi_points.reshape(-1, 2)
                    roi_points_abs = roi_points + np.array([x1, y1])
                    prev_points, status, _ = cv2.calcOpticalFlowPyrLK(
                        prev_gray, current_gray,
                        roi_points_abs.astype(np.float32), None
                    )
                    valid = status.flatten() == 1
                    if np.sum(valid) > 0:
                        flow = np.mean(prev_points[valid] - roi_points_abs[valid], axis=0)
                        optical_flow_center = (prev_fused_center[0] + flow[0], prev_fused_center[1] + flow[1])
                        fused_x = ALPHA * yolo_x + (1 - ALPHA) * optical_flow_center[0]
                        fused_y = ALPHA * yolo_y + (1 - ALPHA) * optical_flow_center[1]

            # Kalman Filter Update
            measurement = np.array([[np.float32(fused_x)], [np.float32(fused_y)]])
            kalman.correct(measurement)
            prediction = kalman.predict()
            pred_x, pred_y = int(prediction[0]), int(prediction[1])
            prev_gray = current_gray.copy()
            prev_fused_center = (fused_x, fused_y)
            dx = pred_x - fixed_position[0]
            dy = pred_y - fixed_position[1]
            distance_pixels = math.hypot(dx, dy)
            distance_cm = distance_pixels * PIXEL_TO_CM
            angle_rad = math.atan2(dy, dx)
            angle_deg = math.degrees(angle_rad)
            correction_x = -dx * PIXEL_TO_CM
            correction_y = -dy * PIXEL_TO_CM

            print("---------------------------------------------------")
            print(" ")
            print("HOVERING_POSITION_FIXED")
            print(" ")
            print(f"HOVERING_POSITION: ({pred_x}, {pred_y})")
            print(" ")
            print(f"Displacement: {distance_cm:.2f} cm at {angle_deg:.2f}°")
            if distance_cm > TOLERANCE_CM:
                print("Command: RETURN to HOVERING_POSITION")
                print(f"-> Correction: Move X: {correction_x:.2f} cm, Y: {correction_y:.2f} cm")
            else:
                print("Status: Within tolerance. No corrective command needed.")
                
            x1, y1, x2, y2 = box
            cv2.rectangle(frame, (x1-2, y1-2), (x2+2, y2+2), (0, 0, 0), thickness=5)
            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), thickness=2)
            cv2.circle(frame, (pred_x, pred_y), 5, (0, 0, 255), -1)
            cv2.putText(frame, f"({pred_x}, {pred_y})", (pred_x + 10, pred_y - 10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
            displacement_text = f"Δx: {dx} px, Δy: {dy} px | {distance_cm:.1f} cm"
            cv2.putText(frame, displacement_text, (x1, y1-20),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)

        cv2.imshow("ANAV HOVERING POSITION ESTIMATION", frame)
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

    cap.release()
    cv2.destroyAllWindows()

if __name__ == '__main__':
    detector = YOLOv8Detector(model_path='yolov8n.pt')
    detect_and_control_ANAV(detector)
